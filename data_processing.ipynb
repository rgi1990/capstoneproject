{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5df96a40-1c58-4dff-9c42-8ee5849166a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully retrieved 503 S&P 500 tickers.\n",
      "\n",
      "Downloading historical stock data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  503 of 503 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data download complete.\n",
      "\n",
      "Processed data saved to processed_stock_data.csv. Rows: 602353\n",
      "\n",
      "Final processed data dtypes:\n",
      "Date                datetime64[ns]\n",
      "Ticker                      object\n",
      "SMA_10                     float64\n",
      "SMA_50                     float64\n",
      "RSI                        float64\n",
      "MACD                       float64\n",
      "MACD_signal                float64\n",
      "upper_band                 float64\n",
      "lower_band                 float64\n",
      "ATR                        float64\n",
      "volume_ratio               float64\n",
      "lagged_return_1d           float64\n",
      "cup_and_handle               int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# data_processing.ipynb\n",
    "\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "import requests\n",
    "\n",
    "# Suppress warnings for a cleaner notebook output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- DATA ACQUISITION: GET ALL S&P 500 TICKERS ---\n",
    "def get_sp500_tickers():\n",
    "    \"\"\"\n",
    "    Fetches a list of S&P 500 tickers from Wikipedia.\n",
    "    \"\"\"\n",
    "    url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "    headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    table = pd.read_html(response.text)\n",
    "    df = table[0]\n",
    "    tickers = df['Symbol'].tolist()\n",
    "    # Yahoo Finance uses BRK-B for Berkshire Hathaway\n",
    "    tickers = [ticker.replace('.', '-') for ticker in tickers]\n",
    "    return tickers\n",
    "\n",
    "try:\n",
    "    tickers = get_sp500_tickers()\n",
    "    print(f\"Successfully retrieved {len(tickers)} S&P 500 tickers.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to retrieve S&P 500 tickers. Using a hardcoded list. Error: {e}\")\n",
    "    tickers = [\n",
    "        'AAPL', 'MSFT', 'GOOGL', 'GOOG', 'AMZN', 'NVDA', 'BRK-B', 'META', 'TSLA', 'UNH',\n",
    "        'LLY', 'JNJ', 'XOM', 'V', 'PG', 'JPM', 'HD', 'MA', 'CVX', 'ABBV', 'PFE', 'AVGO',\n",
    "        'KO', 'PEP', 'BAC', 'MRK', 'COST', 'WMT', 'MCD', 'TMO', 'CSCO', 'DIS', 'NFLX',\n",
    "        'ACN', 'DHR', 'ADBE', 'NKE', 'ORCL', 'VZ', 'CRM', 'TXN', 'CMCSA', 'SBUX', 'PM',\n",
    "        'HON', 'INTC', 'UNP', 'SCHW', 'AXP', 'IBM'\n",
    "    ]\n",
    "\n",
    "# Download historical data for the last 5 years\n",
    "# NOTE: Downloading a large number of tickers may lead to rate limiting.\n",
    "# If you get errors, you may need to add a delay between downloads.\n",
    "print(\"\\nDownloading historical stock data...\")\n",
    "data = yf.download(tickers, period=\"5y\", group_by='ticker')\n",
    "print(\"Data download complete.\")\n",
    "\n",
    "# Restructure the multi-level column index into a single DataFrame\n",
    "all_data = pd.DataFrame()\n",
    "for ticker in tickers:\n",
    "    if ticker in data.columns:\n",
    "        stock_df = data[ticker].copy()\n",
    "        stock_df['Ticker'] = ticker\n",
    "        all_data = pd.concat([all_data, stock_df])\n",
    "\n",
    "# Reset the index and prepare the data for feature engineering\n",
    "all_data.reset_index(inplace=True)\n",
    "all_data.sort_values(by=['Ticker', 'Date'], inplace=True)\n",
    "all_data.rename(columns={'index': 'Date'}, inplace=True)\n",
    "\n",
    "\n",
    "# --- FEATURE ENGINEERING AND ADVANCED PATTERN LABELING ---\n",
    "\n",
    "def find_cup_and_handle(df, cup_depth_pct=0.2, handle_retracement_pct=0.5, lookback_period=60, uptrend_lookback=250):\n",
    "    \"\"\"\n",
    "    Advanced function to detect a cup and handle pattern.\n",
    "    This version includes a new condition for a preceding uptrend.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Calculate rolling statistics over the lookback period\n",
    "    df['rolling_max'] = df['High'].rolling(window=lookback_period).max().shift(1)\n",
    "    df['rolling_min'] = df['Low'].rolling(window=lookback_period).min().shift(1)\n",
    "    \n",
    "    # Calculate the depth of the potential cup\n",
    "    cup_depth = df['rolling_max'] - df['rolling_min']\n",
    "    \n",
    "    # Condition 1: Check for a \"cup\" shape\n",
    "    # The price at the end of the cup should be near the price at the beginning\n",
    "    is_cup_shape = (df['rolling_max'] - df['Close']) / cup_depth < cup_depth_pct\n",
    "    \n",
    "    # Condition 2: Check for a \"handle\"\n",
    "    # The handle should be a slight downward or sideways movement\n",
    "    # and should not retrace more than a certain percentage of the cup's depth.\n",
    "    is_handle_formed = (df['High'] < df['rolling_max']) & \\\n",
    "                       ((df['rolling_max'] - df['Low']) / cup_depth < handle_retracement_pct)\n",
    "    \n",
    "    # Condition 3: Volume confirmation (volume should decrease during cup and handle)\n",
    "    df['rolling_volume_avg'] = df['Volume'].rolling(window=20).mean().shift(1)\n",
    "    is_low_volume = (df['Volume'] < df['rolling_volume_avg'])\n",
    "\n",
    "    # NEW Condition 4: Check for a preceding uptrend\n",
    "    # We check if the price 250 days ago was significantly lower than the current price\n",
    "    df['pre_cup_uptrend'] = (df['Close'] > df['Close'].shift(uptrend_lookback) * 1.20)\n",
    "\n",
    "    # Combine all conditions\n",
    "    df['cup_and_handle'] = np.where(is_cup_shape & is_handle_formed & is_low_volume & df['pre_cup_uptrend'], 1, 0)\n",
    "    \n",
    "    return df['cup_and_handle']\n",
    "\n",
    "\n",
    "def create_features(df):\n",
    "    \"\"\"\n",
    "    Creates a more robust set of technical indicator features for a single stock dataframe.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Moving Averages\n",
    "    df['SMA_10'] = df['Close'].rolling(window=10).mean()\n",
    "    df['SMA_50'] = df['Close'].rolling(window=50).mean()\n",
    "    \n",
    "    # RSI (Relative Strength Index)\n",
    "    delta = df['Close'].diff()\n",
    "    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "    rs = gain / loss\n",
    "    df['RSI'] = 100 - (100 / (1 + rs))\n",
    "    \n",
    "    # MACD (Moving Average Convergence Divergence)\n",
    "    ema_12 = df['Close'].ewm(span=12, adjust=False).mean()\n",
    "    ema_26 = df['Close'].ewm(span=26, adjust=False).mean()\n",
    "    df['MACD'] = ema_12 - ema_26\n",
    "    df['MACD_signal'] = df['MACD'].ewm(span=9, adjust=False).mean()\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    df['SMA_20'] = df['Close'].rolling(window=20).mean()\n",
    "    df['std_20'] = df['Close'].rolling(window=20).std()\n",
    "    df['upper_band'] = df['SMA_20'] + (df['std_20'] * 2)\n",
    "    df['lower_band'] = df['SMA_20'] - (df['std_20'] * 2)\n",
    "    \n",
    "    # Average True Range (ATR)\n",
    "    high_low = df['High'] - df['Low']\n",
    "    high_close = np.abs(df['High'] - df['Close'].shift())\n",
    "    low_close = np.abs(df['Low'] - df['Close'].shift())\n",
    "    ranges = pd.concat([high_low, high_close, low_close], axis=1)\n",
    "    true_range = np.max(ranges, axis=1)\n",
    "    df['ATR'] = true_range.rolling(window=14).mean()\n",
    "    \n",
    "    # Volume features\n",
    "    df['volume_ratio'] = df['Volume'] / df['Volume'].rolling(window=20).mean()\n",
    "    df['lagged_return_1d'] = df['Close'].pct_change(periods=1)\n",
    "    \n",
    "    # We return only the engineered features\n",
    "    return df.drop(columns=['Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close', 'SMA_20', 'std_20'], errors='ignore')\n",
    "\n",
    "\n",
    "all_processed_data = pd.DataFrame()\n",
    "for ticker in all_data['Ticker'].unique():\n",
    "    stock_df = all_data[all_data['Ticker'] == ticker].copy()\n",
    "    \n",
    "    features_df = create_features(stock_df)\n",
    "    cup_and_handle_labels = find_cup_and_handle(stock_df)\n",
    "    \n",
    "    processed_df = pd.concat([\n",
    "        stock_df.reset_index(drop=True),\n",
    "        features_df.reset_index(drop=True),\n",
    "        cup_and_handle_labels.rename('cup_and_handle').reset_index(drop=True)\n",
    "    ], axis=1)\n",
    "    \n",
    "    processed_df = processed_df.loc[:,~processed_df.columns.duplicated()]\n",
    "    all_processed_data = pd.concat([all_processed_data, processed_df], ignore_index=True)\n",
    "\n",
    "all_processed_data.dropna(inplace=True)\n",
    "all_processed_data = all_processed_data.drop(columns=['Close', 'High', 'Low', 'Open', 'Volume', 'Adj Close'], errors='ignore')\n",
    "\n",
    "output_file = 'processed_stock_data.csv'\n",
    "all_processed_data.to_csv(output_file, index=False)\n",
    "print(f\"\\nProcessed data saved to {output_file}. Rows: {len(all_processed_data)}\")\n",
    "print(\"\\nFinal processed data dtypes:\")\n",
    "print(all_processed_data.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95c27f6-c97d-4620-a3de-32d6bfdf3bca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
